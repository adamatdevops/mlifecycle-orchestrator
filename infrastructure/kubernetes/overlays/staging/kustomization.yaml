# =============================================================================
# Staging Environment Overlay
# =============================================================================

apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: ml-inference-staging

resources:
  - ../../base

namePrefix: staging-

commonLabels:
  environment: staging

# Staging-specific image
images:
  - name: inference-service
    newName: ghcr.io/mlifecycle-orchestrator/inference-service
    newTag: staging

# Staging patches
patches:
  # Standard replicas for staging
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: inference-service
      spec:
        replicas: 2
        template:
          spec:
            containers:
              - name: inference
                resources:
                  requests:
                    cpu: "250m"
                    memory: "512Mi"
                  limits:
                    cpu: "1000m"
                    memory: "1Gi"

  # Moderate HPA for staging
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: inference-service
      spec:
        minReplicas: 2
        maxReplicas: 10

configMapGenerator:
  - name: inference-config
    behavior: merge
    literals:
      - LOG_LEVEL=INFO
      - MODEL_URI=s3://mlifecycle-models-staging/models
