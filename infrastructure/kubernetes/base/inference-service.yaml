# =============================================================================
# Inference Service
# =============================================================================
# Kubernetes Service for ML inference endpoints.
# =============================================================================

apiVersion: v1
kind: Service
metadata:
  name: inference-service
  labels:
    app: inference-service
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
  selector:
    app: inference-service

---
# Ingress (optional - for external access)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: inference-service
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
    - hosts:
        - inference.example.com  # Replace with actual domain
      secretName: inference-tls
  rules:
    - host: inference.example.com  # Replace with actual domain
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: inference-service
                port:
                  number: 80
